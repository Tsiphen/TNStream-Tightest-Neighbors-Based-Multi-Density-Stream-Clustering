"""
TNStream Annoyç‰ˆæœ¬ - è¿è¡Œè„šæœ¬
ä½¿ç”¨Annoyç´¢å¼•çš„è½»é‡é«˜é€Ÿç‰ˆæœ¬
ä¿®æ”¹è¯´æ˜ï¼šå¯¼å…¥TNStreamç±»è€Œä¸æ˜¯TNStreamAnnoy
"""

import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics.cluster import adjusted_rand_score
from sklearn.metrics import normalized_mutual_info_score
from TNStream_Annoy import TNStream  # âœ“ ä¿®æ”¹ï¼šå¯¼å…¥TNStreamè€Œä¸æ˜¯TNStreamAnnoy
import time
import json
from datetime import datetime
import os

# åŠ è½½æ•°æ®é›†
print("="*70)
print("TNStream Annoyç‰ˆæœ¬ - æ€§èƒ½æµ‹è¯•")
print("="*70)

dataset = np.loadtxt("/Users/tsiphenzeng/Desktop/TNStream/dataset/dataset2/kdd_converted.txt", dtype=float, delimiter=' ')
X = dataset[:, :-1]
labels_true = dataset[:, -1]

print(f"\næ•°æ®é›†å¤§å°: {X.shape[0]} æ ·æœ¬, {X.shape[1]} ç»´")
print(f"çœŸå®ç±»åˆ«æ•°: {len(np.unique(labels_true))}")

# æ ‡å‡†åŒ–åªåšä¸€æ¬¡
print("\næ•°æ®æ ‡å‡†åŒ–...")
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)
print("âœ“ æ ‡å‡†åŒ–å®Œæˆ")

# å‚æ•°è®¾ç½®
dataset_name = "KDD"
W = 4288
N = 3
r = 0.701
n_micro = 8
k = 4
mk = 4

print(f"\nå‚æ•°é…ç½®:")
print(f"  W (çª—å£å¤§å°) = {W}")
print(f"  N (å¾®ç°‡æœ€å°ç‚¹æ•°) = {N}")
print(f"  r (å¾®ç°‡åŠå¾„) = {r}")
print(f"  n_micro (å®ç°‡æœ€å°å¾®ç°‡æ•°) = {n_micro}")
print(f"  k (k-NNå‚æ•°) = {k}")
print(f"  mk (å…±äº«è¿‘é‚»æ•°) = {mk}")

# ç»“æœå­˜å‚¨
results = []
best_ari = -1
best_nmi = -1
best_purity = 0
best_result = None

# åˆ›å»ºæ—¥å¿—æ–‡ä»¶
log_file = f"tnstream_run_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
results_file = f"tnstream_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
best_file = f"tnstream_best_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

def log_message(msg):
    """è®°å½•åˆ°æ–‡ä»¶å’Œæ§åˆ¶å°"""
    print(msg)
    with open(log_file, 'a', encoding='utf-8') as f:
        f.write(msg + '\n')

log_message("="*70)
log_message(f"å¼€å§‹æ—¶é—´: {datetime.now()}")
log_message("="*70)

print(f"\n{'='*70}")
print("å¼€å§‹è¿è¡Œ TNStream Annoyç‰ˆæœ¬")
print(f"{'='*70}\n")

T = 0
while T < 1000:
    T += 1

    print(f"[è¿­ä»£ {T}/1000]", end=" ", flush=True)

    start = time.time()

    try:
        # âœ“ ä¿®æ”¹ï¼šä½¿ç”¨TNStreamç±»
        model = TNStream(
            X_scaled.copy(),
            labels_true.copy(),
            N=N,
            W=W,
            r=r,
            n_micro=n_micro,
            d=X.shape[1],
            plotFigure=0,
            k=k,
            mk=mk
        )

        elapsed = time.time() - start

        # è¶…æ—¶æ£€æŸ¥
        if elapsed > 60 * 20:
            print(f"è¶…æ—¶ ({elapsed:.1f}s), è·³è¿‡")
            continue

        # è¯„ä¼°ç»“æœ
        metrics_dict = model.evaluate()
        ARI = metrics_dict['ARI']
        Purity = metrics_dict['Purity']
        NMI = metrics_dict['NMI']

        print(f"ç”¨æ—¶: {elapsed:.2f}s | Purity: {Purity:.4f} | ARI: {ARI:.4f} | NMI: {NMI:.4f}", flush=True)

        # ä¿å­˜ç»“æœ
        result = {
            'iteration': T,
            'dataset': dataset_name,
            'params': {
                'W': W, 'N': N, 'r': r, 'n_micro': n_micro, 'k': k, 'mk': mk
            },
            'time': elapsed,
            'purity': Purity,
            'ari': ARI,
            'nmi': NMI,
            'num_mcs': len(model.MCs),
            'num_macro_cs': len(model.MacroClusters),
            'timestamp': datetime.now().isoformat()
        }
        results.append(result)

        # æ›´æ–°æœ€ä¼˜ç»“æœï¼ˆå¤šä¸ªæŒ‡æ ‡ç»¼åˆè€ƒè™‘ï¼‰
        combined_score = 0.4 * ARI + 0.3 * NMI + 0.3 * Purity
        best_combined = 0.4 * best_ari + 0.3 * best_nmi + 0.3 * best_purity if best_ari >= 0 else -1

        if combined_score > best_combined:
            best_ari = ARI
            best_nmi = NMI
            best_purity = Purity
            best_result = result
            print(f"  â­ æ–°çš„æœ€ä¼˜ç»“æœï¼(ARI: {ARI:.4f})")

        # è¾¾åˆ°ä¼˜ç§€æ°´å¹³æ—¶æ‰“å°è¯¦ç»†ä¿¡æ¯
        if ARI > 0.5 and NMI > 0.4:
            detail_msg = f"\n{'='*70}\nğŸ† ä¼˜ç§€ç»“æœ (è¿­ä»£ {T})\n{'='*70}\n"
            detail_msg += f"æ•°æ®é›†: {dataset_name}\n"
            detail_msg += f"å‚æ•°: N={N}, r={r:.3f}, mk={mk}, n_micro={n_micro}\n"
            detail_msg += f"\nã€æ€§èƒ½æŒ‡æ ‡ã€‘\n"
            detail_msg += f"  è¿è¡Œæ—¶é—´: {elapsed:.2f}s\n"
            detail_msg += f"  å¾®ç°‡æ•°: {len(model.MCs)}\n"
            detail_msg += f"  å®ç°‡æ•°: {len(model.MacroClusters)}\n"
            detail_msg += f"\nã€èšç±»è´¨é‡ã€‘\n"
            detail_msg += f"  Purity = {Purity:.4f}\n"
            detail_msg += f"  ARI = {ARI:.4f}\n"
            detail_msg += f"  NMI = {NMI:.4f}\n"
            detail_msg += f"{'='*70}\n"
            log_message(detail_msg)

        # æ¯10æ¬¡ä¿å­˜ä¸€æ¬¡æ‰€æœ‰ç»“æœ
        if T % 10 == 0:
            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)

    except Exception as e:
        print(f"é”™è¯¯: {str(e)[:100]}")
        continue

# æœ€ç»ˆæ€»ç»“
print(f"\n{'='*70}")
print("è¿è¡Œå®Œæˆï¼")
print(f"{'='*70}\n")

if best_result:
    summary = f"""
ã€æœ€ä¼˜ç»“æœæ€»ç»“ã€‘
  è¿­ä»£: {best_result['iteration']}
  Purity: {best_result['purity']:.6f}
  ARI: {best_result['ari']:.6f}
  NMI: {best_result['nmi']:.6f}
  è¿è¡Œæ—¶é—´: {best_result['time']:.2f}s
  å¾®ç°‡æ•°: {best_result['num_mcs']}
  å®ç°‡æ•°: {best_result['num_macro_cs']}
  
  å‚æ•°:
    N = {best_result['params']['N']}
    r = {best_result['params']['r']}
    mk = {best_result['params']['mk']}
    n_micro = {best_result['params']['n_micro']}
    k = {best_result['params']['k']}
"""
    print(summary)
    log_message(summary)

    # ä¿å­˜æœ€ç»ˆç»“æœ
    with open(best_file, 'w', encoding='utf-8') as f:
        json.dump(best_result, f, indent=2, ensure_ascii=False)

    print(f"âœ“ æœ€ä¼˜ç»“æœå·²ä¿å­˜åˆ°: {best_file}")

# ä¿å­˜æ‰€æœ‰ç»“æœ
with open(results_file, 'w', encoding='utf-8') as f:
    json.dump(results, f, indent=2, ensure_ascii=False)

print(f"âœ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
print(f"âœ“ è¿è¡Œæ—¥å¿—å·²ä¿å­˜åˆ°: {log_file}")

# æ‰“å°TOP 5ç»“æœ
if results:
    print(f"\n{'='*70}")
    print("TOP 5 (æŒ‰ARIæ’åº)")
    print(f"{'='*70}")
    top_results = sorted(results, key=lambda x: x['ari'], reverse=True)[:5]
    for i, r in enumerate(top_results, 1):
        print(f"{i}. ARI={r['ari']:.4f}, NMI={r['nmi']:.4f}, Purity={r['purity']:.4f}, æ—¶é—´={r['time']:.2f}s")

print(f"\næ€»å…±å®Œæˆ {len(results)} æ¬¡æœ‰æ•ˆè¿è¡Œ\n")